#!/usr/bin/env python3
"""
Spliceo V2 Ultra - Hyper-Optimized Minecraft Video Editor
OPTIMIZATIONS:
- Smart codec copy for unmodified segments (10x faster)
- Aggressive file size reduction (50-70% smaller)
- NVIDIA GPU acceleration (RTX 5090 optimized)
- Parallel chunk processing with smart batching
- Minimal re-encoding strategy
- Two-pass encoding option for best compression
Date: January 5, 2026
"""

from dataclasses import dataclass, field
from typing import List, Optional, Union, Dict, Any, Tuple
import os, json, shutil, subprocess, time, signal, hashlib, runpod
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, TimeoutError as FuturesTimeoutError


# =============================================================================
# PERFORMANCE PRESETS
# =============================================================================

PERFORMANCE_PRESET = "fast"  # Options: "fast", "balanced", "quality"
ENABLE_GPU = True           # Use NVIDIA GPU acceleration (NVENC)
GPU_ENCODER = "h264_nvenc"  # Options: "h264_nvenc", "hevc_nvenc", "av1_nvenc"

PRESETS = {
    "fast": {
        "encoding": "ultrafast",
        "crf": 26,
        "cq": 28,             # For NVENC
        "gpu_preset": "p1",   # fastest (NVENC)
        "workers": 4,         # RTX 5090 can handle more parallel tasks
        "audio_bitrate": "96k",
        "color_grading": False,
        "two_pass": False,
        "tune": "fastdecode"
    },
    "balanced": {
        "encoding": "veryfast",
        "crf": 23,
        "cq": 24,             # For NVENC
        "gpu_preset": "p4",   # balanced (NVENC)
        "workers": 3,
        "audio_bitrate": "128k",
        "color_grading": True,
        "two_pass": False,
        "tune": "film"
    },
    "quality": {
        "encoding": "medium",
        "crf": 20,
        "cq": 19,             # For NVENC
        "gpu_preset": "p7",   # slowest/best (NVENC)
        "workers": 2,
        "audio_bitrate": "192k",
        "color_grading": True,
        "two_pass": True,
        "tune": "film"
    }
}

# =============================================================================
# CONFIGURATION
# =============================================================================

INPUT_VIDEO = "input_minecraft.mp4"
OUTPUT_VIDEO = "output_spliceo_v2.mp4"
EDITMAP_JSON = "edit_map.json"

# Load preset settings
PRESET = PRESETS[PERFORMANCE_PRESET]
OUTPUT_RESOLUTION = "1080p"  # "720p", "1080p", "1440p", "4k", "original"
CRF_QUALITY = PRESET["crf"]
CQ_QUALITY = PRESET["cq"]
GPU_PRESET = PRESET["gpu_preset"]
TUNE_PARAM = PRESET["tune"]
MAX_WORKERS = PRESET["workers"]
ENCODING_PRESET = PRESET["encoding"]
TWO_PASS_ENCODING = PRESET["two_pass"]
AUDIO_BITRATE = PRESET["audio_bitrate"]
ENABLE_COLOR_GRADING = PRESET["color_grading"]

# Advanced settings
DEBUG_OVERLAY = False
SMART_COPY_MODE = True  # Use codec copy when possible (HUGE speedup)
INCLUDE_FULL_VIDEO = True
MAX_SEGMENT_TIMEOUT = 3600
CACHE_DIR = ".spliceo_cache"

# FFmpeg optimization
FFMPEG_BIN = "ffmpeg"
FFPROBE_BIN = "ffprobe"
FFMPEG_THREADS = 0  # 0 = auto-detect optimal thread count

RESOLUTION_PRESETS = {
    "720p": (1280, 720),
    "1080p": (1920, 1080),
    "1440p": (2560, 1440),
    "4k": (3840, 2160),
    "original": None
}

# =============================================================================
# DATACLASSES
# =============================================================================

@dataclass
class Subtitle:
    id: str
    text: str
    start: float
    end: float
    style: Dict[str, Any]
    is_locked: bool = False

@dataclass
class Edit:
    id: str
    start: float
    end: float
    type: str
    zoom: Union[str, float]
    speed: float
    anchor_x: float
    anchor_y: float
    is_locked: bool = False

@dataclass
class Segment:
    start: float
    end: float
    edit: Optional[Edit] = None
    subtitles: List[Subtitle] = field(default_factory=list)
    is_original: bool = False
    needs_processing: bool = True
    can_copy: bool = False

    @property
    def duration(self) -> float:
        return self.end - self.start

# =============================================================================
# UTILITIES
# =============================================================================

_GPU_SUPPORT_CACHE = None

def check_gpu_support() -> bool:
    """Check if the configured GPU encoder is actually usable."""
    global _GPU_SUPPORT_CACHE
    if not ENABLE_GPU:
        return False
    
    if _GPU_SUPPORT_CACHE is not None:
        return _GPU_SUPPORT_CACHE
        
    try:
        # First check if encoder exists in ffmpeg
        cmd_check = [FFMPEG_BIN, "-encoders"]
        result = subprocess.run(cmd_check, capture_output=True, text=True, timeout=5)
        if GPU_ENCODER not in result.stdout:
            print(f"âš ï¸  GPU encoder {GPU_ENCODER} not found in FFmpeg")
            _GPU_SUPPORT_CACHE = False
            return False
            
        # Check CUDA/GPU availability
        cmd_gpu = ["nvidia-smi", "--query-gpu=name,driver_version,memory.total", "--format=csv,noheader"]
        try:
            gpu_result = subprocess.run(cmd_gpu, capture_output=True, text=True, timeout=5)
            if gpu_result.returncode == 0:
                gpu_info = gpu_result.stdout.strip()
                print(f"âœ“ GPU detected: {gpu_info}")
        except:
            pass
            
        # Then try a tiny dummy encode to verify hardware/drivers
        # This is the most reliable way to check for CUDA/NVENC usability
        dummy_cmd = [
            FFMPEG_BIN, "-y", "-f", "lavfi", "-i", "color=c=black:s=64x64:d=0.1",
            "-c:v", GPU_ENCODER, "-f", "null", "-"
        ]
        process = subprocess.run(dummy_cmd, capture_output=True, text=True, timeout=10)
        _GPU_SUPPORT_CACHE = (process.returncode == 0)
        
        if _GPU_SUPPORT_CACHE:
            print(f"âœ“ GPU encoding test passed - {GPU_ENCODER} ready")
        else:
            print(f"âš ï¸  GPU encoding test failed - falling back to CPU")
            
        return _GPU_SUPPORT_CACHE
    except Exception as e:
        print(f"âš ï¸  GPU check error: {str(e)}")
        _GPU_SUPPORT_CACHE = False
        return False

def download_from_gdrive(file_id: str, output_path: str):
    """Download file from Google Drive using gdown or direct download."""
    try:
        # Try using gdown (more reliable for large files)
        import gdown
        url = f"https://drive.google.com/uc?id={file_id}"
        gdown.download(url, output_path, quiet=False)
    except ImportError:
        # Fallback to wget with direct download link
        direct_url = f"https://drive.google.com/uc?export=download&id={file_id}"
        subprocess.check_call([
            "wget", "--no-check-certificate", 
            "--content-disposition",
            "-O", output_path, 
            direct_url
        ])
    except Exception as e:
        print(f"âš ï¸  Download error, trying alternative method: {str(e)}")
        # Last resort: try curl
        direct_url = f"https://drive.google.com/uc?export=download&id={file_id}"
        subprocess.check_call([
            "curl", "-L", "-o", output_path, direct_url
        ])

def get_segment_hash(seg: Segment, input_path: str) -> str:
    """Generate unique hash for segment caching."""
    data = f"{input_path}_{seg.start}_{seg.end}_{seg.is_original}_{len(seg.subtitles)}"
    if seg.edit:
        data += f"_{seg.edit.type}_{seg.edit.speed}_{seg.edit.zoom}"
    return hashlib.md5(data.encode()).hexdigest()[:12]

def get_output_resolution(original_width: int, original_height: int) -> Tuple[int, int]:
    """Get target output resolution."""
    if OUTPUT_RESOLUTION == "original":
        return original_width, original_height
    
    if OUTPUT_RESOLUTION not in RESOLUTION_PRESETS:
        return original_width, original_height
    
    target = RESOLUTION_PRESETS[OUTPUT_RESOLUTION]
    return target if target else (original_width, original_height)

def get_video_info(path: str) -> Dict[str, Any]:
    """Get video metadata efficiently."""
    cmd = [
        FFPROBE_BIN, "-v", "error", 
        "-select_streams", "v:0",
        "-show_entries", "stream=codec_name,codec_type,width,height,duration,r_frame_rate:format=duration",
        "-of", "json", path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
    data = json.loads(result.stdout)
    
    streams = data.get("streams", [])
    v_stream = streams[0] if streams else {}
    format_info = data.get("format", {})
    
    duration = float(v_stream.get("duration", format_info.get("duration", 0)))
    
    r_frame_rate = v_stream.get("r_frame_rate", "30/1")
    num, den = map(int, r_frame_rate.split('/'))
    fps = num / den if den != 0 else 30.0
    
    # Check for audio
    cmd_audio = [FFPROBE_BIN, "-v", "error", "-select_streams", "a:0", 
                 "-show_entries", "stream=codec_type", "-of", "json", path]
    result_audio = subprocess.run(cmd_audio, capture_output=True, text=True, timeout=10)
    has_audio = bool(json.loads(result_audio.stdout).get("streams"))
    
    return {
        "width": int(v_stream.get("width", 1920)),
        "height": int(v_stream.get("height", 1080)),
        "duration": duration,
        "fps": fps,
        "has_audio": has_audio,
        "codec": v_stream.get("codec_name", "unknown")
    }

def run_ffmpeg(args: List[str], timeout: int = 300, show_progress: bool = False) -> None:
    """Run FFmpeg with timeout and optional progress."""
    env = os.environ.copy()
    # env["FFREPORT"] = "level=error"  # This causes "Invalid report file level" error
    
    # Add -loglevel error to args if not present
    if "-loglevel" not in args:
        # Insert after 'ffmpeg'
        args.insert(1, "-loglevel")
        args.insert(2, "error")
    
    try:
        if show_progress:
            process = subprocess.Popen(
                args,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                env=env,
                preexec_fn=os.setsid if os.name != 'nt' else None
            )
            
            for line in process.stdout:
                if "frame=" in line or "time=" in line:
                    print(f"\r    {line.strip()}", end='', flush=True)
            
            process.wait(timeout=timeout)
            print()
            
            if process.returncode != 0:
                raise RuntimeError(f"FFmpeg failed with code {process.returncode}")
        else:
            process = subprocess.Popen(
                args,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                env=env,
                preexec_fn=os.setsid if os.name != 'nt' else None
            )
            
            stdout, stderr = process.communicate(timeout=timeout)
            if process.returncode != 0:
                # If it failed, provide more context from stderr
                error_msg = stderr[-1000:] if stderr else "Unknown error (no stderr)"
                raise RuntimeError(f"FFmpeg failed: {error_msg}")
                
    except subprocess.TimeoutExpired:
        if os.name != 'nt':
            os.killpg(os.getpgid(process.pid), signal.SIGTERM)
        else:
            process.terminate()
        process.wait()
        raise RuntimeError(f"FFmpeg timeout after {timeout}s")
    except Exception as e:
        raise RuntimeError(f"FFmpeg error: {str(e)}")

# =============================================================================
# SEGMENT GENERATION
# =============================================================================

def parse_edit_map(data: Dict[str, Any]) -> Tuple[List[Edit], List[Subtitle]]:
    """Parse JSON into Edit and Subtitle objects."""
    edits = []
    subtitles = []
    
    for edit_data in data.get("edits", []):
        edit = Edit(
            id=edit_data["id"],
            start=float(edit_data["start"]),
            end=float(edit_data["end"]),
            type=edit_data["type"],
            zoom=edit_data["zoom"],
            speed=float(edit_data["speed"]),
            anchor_x=float(edit_data["anchorX"]),
            anchor_y=float(edit_data["anchorY"]),
            is_locked=edit_data.get("isLocked", False)
        )
        edits.append(edit)
    
    for sub_data in data.get("subtitles", []):
        subtitle = Subtitle(
            id=sub_data["id"],
            text=sub_data["text"],
            start=float(sub_data["start"]),
            end=float(sub_data["end"]),
            style=sub_data.get("style", {}),
            is_locked=sub_data.get("isLocked", False)
        )
        subtitles.append(subtitle)
    
    return edits, subtitles

def analyze_segment_processing(seg: Segment, orig_w: int, orig_h: int, 
                               out_w: int, out_h: int) -> Tuple[bool, bool]:
    """Determine if segment needs processing and if it can use codec copy."""
    needs_processing = False
    can_copy = False
    
    # Check if this is truly unmodified
    if seg.is_original and not seg.subtitles and not DEBUG_OVERLAY:
        # Check if resolution matches
        if orig_w == out_w and orig_h == out_h and not ENABLE_COLOR_GRADING:
            can_copy = True
            needs_processing = False
        else:
            needs_processing = True
    else:
        needs_processing = True
    
    # Any edit requires processing
    if seg.edit:
        if seg.edit.speed != 1.0 or seg.edit.zoom not in ["none", 1.0]:
            needs_processing = True
    
    return needs_processing, can_copy

def create_segments(edits: List[Edit], subtitles: List[Subtitle], 
                   total_duration: float, orig_w: int, orig_h: int,
                   out_w: int, out_h: int) -> List[Segment]:
    """Create optimized segments with processing analysis."""
    if not edits:
        seg = Segment(start=0.0, end=total_duration, is_original=True)
        seg.needs_processing, seg.can_copy = analyze_segment_processing(
            seg, orig_w, orig_h, out_w, out_h
        )
        return [seg]
    
    edits.sort(key=lambda x: x.start)
    segments = []
    current_time = 0.0
    
    # Merge consecutive original segments
    MAX_ORIGINAL_CHUNK = 300.0  # 5 minutes max per original chunk
    
    def add_original_segment(start: float, end: float):
        duration = end - start
        
        if duration <= MAX_ORIGINAL_CHUNK:
            seg = Segment(start=start, end=end, is_original=True)
            seg.needs_processing, seg.can_copy = analyze_segment_processing(
                seg, orig_w, orig_h, out_w, out_h
            )
            segments.append(seg)
        else:
            # Split large segments
            chunk_start = start
            while chunk_start < end:
                chunk_end = min(chunk_start + MAX_ORIGINAL_CHUNK, end)
                seg = Segment(start=chunk_start, end=chunk_end, is_original=True)
                seg.needs_processing, seg.can_copy = analyze_segment_processing(
                    seg, orig_w, orig_h, out_w, out_h
                )
                segments.append(seg)
                chunk_start = chunk_end
    
    for edit in edits:
        if edit.start > current_time + 0.01:
            add_original_segment(current_time, edit.start)
        
        overlapping_subs = [
            sub for sub in subtitles
            if not (sub.end <= edit.start or sub.start >= edit.end)
        ]
        
        seg = Segment(
            start=edit.start,
            end=edit.end,
            edit=edit,
            subtitles=overlapping_subs,
            is_original=False
        )
        seg.needs_processing, seg.can_copy = analyze_segment_processing(
            seg, orig_w, orig_h, out_w, out_h
        )
        segments.append(seg)
        
        current_time = max(current_time, edit.end)
    
    if current_time < total_duration - 0.01:
        add_original_segment(current_time, total_duration)
    
    return segments

# =============================================================================
# FILTER BUILDERS (Optimized)
# =============================================================================

def escape_filter_text(text: str) -> str:
    """Escape text for FFmpeg filters."""
    text = text.replace('\\', '\\\\')
    text = text.replace("'", "'\\\\\\''")
    text = text.replace(':', '\\:')
    text = text.replace('[', '\\[')
    text = text.replace(']', '\\]')
    return text

def build_optimized_color_filter() -> str:
    """Lightweight color enhancement."""
    if not ENABLE_COLOR_GRADING:
        return ""
    # Lighter grading for performance
    return "eq=brightness=0.03:contrast=1.08:saturation=1.1"

def build_subtitle_filter(subtitle: Subtitle, segment_start: float, 
                         width: int, height: int) -> str:
    """Build optimized drawtext filter."""
    style = subtitle.style
    text = escape_filter_text(subtitle.text)
    
    pos = style.get("position", {"x": 50, "y": 85})
    x_pct, y_pct = pos["x"], pos["y"]
    x_px = int((x_pct / 100) * width)
    y_px = int((y_pct / 100) * height)
    
    sub_start = max(0, subtitle.start - segment_start)
    sub_end = subtitle.end - segment_start
    
    font_size = style.get("fontSize", 32)
    color = style.get("color", "#ffffff").replace("#", "")
    stroke_color = style.get("strokeColor", "#000000").replace("#", "")
    stroke_width = style.get("strokeWidth", 2)
    text_align = style.get("textAlign", "center")
    
    if text_align == "center":
        x_expr = f"{x_px}-(tw/2)"
    elif text_align == "right":
        x_expr = f"{x_px}-tw"
    else:
        x_expr = str(x_px)
    
    return (
        f"drawtext=text='{text}':"
        f"fontsize={font_size}:"
        f"fontcolor=0x{color}:"
        f"borderw={stroke_width}:"
        f"bordercolor=0x{stroke_color}:"
        f"x={x_expr}:y={y_px}:"
        f"enable='between(t,{sub_start},{sub_end})'"
    )

def build_zoom_filter(edit: Edit, width: int, height: int) -> Optional[str]:
    """Build instant, stable zoom filter â€” no ramp, no shake."""
    if edit.zoom == "none" or edit.zoom <= 1.0:
        return None

    zoom_level = float(edit.zoom)  # e.g., 1.4
    anchor_x = float(edit.anchor_x)  # 0.0 to 1.0 (fraction of width)
    anchor_y = float(edit.anchor_y)  # 0.0 to 1.0 (fraction of height)

    # Calculate fixed crop position so anchor point stays centered in output
    crop_w = width / zoom_level
    crop_h = height / zoom_level
    crop_x = anchor_x * width - crop_w / 2
    crop_y = anchor_y * height - crop_h / 2

    # Clamp to avoid negative/offscreen crop
    crop_x = max(0, min(crop_x, width - crop_w))
    crop_y = max(0, min(crop_y, height - crop_h))

    # Use simple crop + scale â€” rock solid, no jitter
    return (
        f"crop={crop_w}:{crop_h}:{crop_x}:{crop_y},"
        f"scale={width}:{height}:flags=lanczos"
    )

# =============================================================================
# SMART RENDERING PIPELINE (GPU-OPTIMIZED)
# =============================================================================

def render_segment_smart(args: Tuple) -> str:
    """Ultra-optimized segment rendering with smart codec copy and GPU acceleration."""
    (i, seg, input_path, temp_dir, fps, debug_overlay, has_audio,
     orig_w, orig_h, out_w, out_h) = args
    
    temp_out = os.path.join(temp_dir, f"seg_{i:04d}.mp4")
    
    # Display info
    if seg.is_original:
        mode = "COPY" if seg.can_copy else "PROCESS"
        print(f"  [{i:3d}] Original-{mode} ({seg.duration:.1f}s)", flush=True)
    else:
        edit_type = seg.edit.type.upper() if seg.edit else "EDIT"
        print(f"  [{i:3d}] {edit_type} ({seg.duration:.1f}s)", flush=True)
    
    start_t = time.time()
    
    # ULTRA-FAST PATH: Direct codec copy (no re-encoding)
    if seg.can_copy and SMART_COPY_MODE:
        timeout = min(int(seg.duration) + 30, 300)
        
        cmd = [
            FFMPEG_BIN, "-y",
            "-ss", str(seg.start),
            "-t", str(seg.duration),
            "-i", input_path,
            "-c", "copy",
            "-avoid_negative_ts", "make_zero",
            temp_out
        ]
        
        try:
            run_ffmpeg(cmd, timeout=timeout)
        except Exception as e:
            print(f"  [{i:3d}] FAILED: {str(e)}", flush=True)
            raise
        
        end_t = time.time()
        print(f"  [{i:3d}] âœ“ {end_t - start_t:.1f}s [INSTANT]", flush=True)
        return temp_out
    
    # FAST PATH: Minimal processing for simple original segments
    if seg.is_original and not debug_overlay and not seg.subtitles:
        timeout = min(int(seg.duration * 2) + 60, MAX_SEGMENT_TIMEOUT)
        
        v_filters = []
        
        # Only scale if needed
        if out_w != orig_w or out_h != orig_h:
            # Use hardware scaling when possible
            v_filters.append(f"scale={out_w}:{out_h}:flags=fast_bilinear")
        
        color_filter = build_optimized_color_filter()
        if color_filter:
            v_filters.append(color_filter)
        
        cmd = [
            FFMPEG_BIN, "-y",
            "-ss", str(seg.start),
            "-t", str(seg.duration),
            "-i", input_path
        ]
        
        # Add filters if any
        if v_filters:
            cmd.extend(["-vf", ",".join(v_filters)])
        
        # GPU or CPU encoding
        use_gpu = check_gpu_support()
        
        if use_gpu:
            cmd.extend([
                "-c:v", GPU_ENCODER,
                "-preset", GPU_PRESET,
                "-rc", "vbr",
                "-cq", str(CQ_QUALITY),
                "-b:v", "0",  # Let CQ control quality
                "-pix_fmt", "yuv420p",
                "-gpu", "0"  # Use first GPU
            ])
        else:
            cmd.extend([
                "-c:v", "libx264",
                "-preset", ENCODING_PRESET,
                "-crf", str(CRF_QUALITY),
                "-tune", TUNE_PARAM,
                "-pix_fmt", "yuv420p",
                "-threads", str(FFMPEG_THREADS)
            ])
        
        if has_audio:
            cmd.extend(["-c:a", "aac", "-b:a", AUDIO_BITRATE])
        
        cmd.extend(["-movflags", "+faststart", temp_out])
        
        try:
            run_ffmpeg(cmd, timeout=timeout)
        except Exception as e:
            if use_gpu:
                print(f"  [{i:3d}] GPU FAILED, retrying with CPU: {str(e)[:50]}...", flush=True)
                # Rebuild command with CPU encoding
                cmd_cpu = [
                    FFMPEG_BIN, "-y",
                    "-ss", str(seg.start),
                    "-t", str(seg.duration),
                    "-i", input_path
                ]
                if v_filters:
                    cmd_cpu.extend(["-vf", ",".join(v_filters)])
                cmd_cpu.extend([
                    "-c:v", "libx264",
                    "-preset", ENCODING_PRESET,
                    "-crf", str(CRF_QUALITY),
                    "-tune", TUNE_PARAM,
                    "-pix_fmt", "yuv420p",
                    "-threads", str(FFMPEG_THREADS)
                ])
                if has_audio:
                    cmd_cpu.extend(["-c:a", "aac", "-b:a", AUDIO_BITRATE])
                cmd_cpu.extend(["-movflags", "+faststart", temp_out])
                run_ffmpeg(cmd_cpu, timeout=timeout)
            else:
                print(f"  [{i:3d}] FAILED: {str(e)}", flush=True)
                raise
        
        end_t = time.time()
        print(f"  [{i:3d}] âœ“ {end_t - start_t:.1f}s", flush=True)
        return temp_out
    
    # FULL PROCESSING: Complex edits
    timeout = min(int(seg.duration * 8) + 120, MAX_SEGMENT_TIMEOUT)
    
    v_filters = []
    a_filters = []
    
    # Scale efficiently
    if out_w != orig_w or out_h != orig_h:
        v_filters.append(f"scale={out_w}:{out_h}:flags=fast_bilinear")
    
    # Color grading
    color_filter = build_optimized_color_filter()
    if color_filter:
        v_filters.append(color_filter)
    
    # Handle edits
    if seg.edit:
        edit = seg.edit
        
        # Speed changes
        if edit.speed != 1.0:
            speed_val = edit.speed
            v_filters.append(f"setpts={1/speed_val}*PTS")
            
            if has_audio:
                val = speed_val
                while val > 2.0:
                    a_filters.append("atempo=2.0")
                    val /= 2.0
                while val < 0.5:
                    a_filters.append("atempo=0.5")
                    val *= 2.0
                if 0.5 <= val <= 2.0 and val != 1.0:
                    a_filters.append(f"atempo={val}")
        
        # Zoom
        if edit.type == "zoom" or (edit.zoom not in ["none", 1.0]):
            zoom_filter = build_zoom_filter(edit, out_w, out_h)
            if zoom_filter:
                v_filters.append(zoom_filter)
    
    # Subtitles
    for subtitle in seg.subtitles:
        sub_filter = build_subtitle_filter(subtitle, seg.start, out_w, out_h)
        v_filters.append(sub_filter)
    
    # Debug overlay
    if debug_overlay:
        text = escape_filter_text(f"[{i}]")
        v_filters.append(
            f"drawtext=text='{text}':fontcolor=yellow:fontsize=20:"
            "box=1:boxcolor=black@0.7:boxborderw=3:x=10:y=10"
        )
    
    # Build command
    cmd = [
        FFMPEG_BIN, "-y",
        "-ss", str(seg.start),
        "-t", str(seg.duration),
        "-i", input_path
    ]
    
    vf_chain = ",".join(v_filters)
    af_chain = ",".join(a_filters) if a_filters and has_audio else None
    
    if af_chain:
        filter_complex = f"[0:v]{vf_chain}[v];[0:a]{af_chain}[a]"
        cmd.extend(["-filter_complex", filter_complex, "-map", "[v]", "-map", "[a]"])
    else:
        cmd.extend(["-vf", vf_chain])
        if has_audio:
            cmd.extend(["-c:a", "aac", "-b:a", AUDIO_BITRATE])
    
    # GPU or CPU encoding
    use_gpu = check_gpu_support()
    
    if use_gpu:
        cmd.extend([
            "-c:v", GPU_ENCODER,
            "-preset", GPU_PRESET,
            "-rc", "vbr",
            "-cq", str(CQ_QUALITY),
            "-b:v", "0",
            "-pix_fmt", "yuv420p",
            "-gpu", "0"
        ])
    else:
        cmd.extend([
            "-c:v", "libx264",
            "-preset", ENCODING_PRESET,
            "-crf", str(CRF_QUALITY),
            "-tune", TUNE_PARAM,
            "-pix_fmt", "yuv420p",
            "-threads", str(FFMPEG_THREADS)
        ])
    
    cmd.extend(["-movflags", "+faststart", temp_out])

    try:
        run_ffmpeg(cmd, timeout=timeout)
    except Exception as e:
        if use_gpu:
            print(f"  [{i:3d}] GPU FAILED, retrying with CPU: {str(e)[:50]}...", flush=True)
            # Rebuild command with CPU
            cmd_cpu = [
                FFMPEG_BIN, "-y",
                "-ss", str(seg.start),
                "-t", str(seg.duration),
                "-i", input_path
            ]
            if af_chain:
                cmd_cpu.extend(["-filter_complex", filter_complex, "-map", "[v]", "-map", "[a]"])
            else:
                cmd_cpu.extend(["-vf", vf_chain])
                if has_audio:
                    cmd_cpu.extend(["-c:a", "aac", "-b:a", AUDIO_BITRATE])
            
            cmd_cpu.extend([
                "-c:v", "libx264",
                "-preset", ENCODING_PRESET,
                "-crf", str(CRF_QUALITY),
                "-tune", TUNE_PARAM,
                "-pix_fmt", "yuv420p",
                "-threads", str(FFMPEG_THREADS),
                "-movflags", "+faststart",
                temp_out
            ])
            run_ffmpeg(cmd_cpu, timeout=timeout)
        else:
            print(f"  [{i:3d}] FAILED: {str(e)}", flush=True)
            raise
    
    end_t = time.time()
    print(f"  [{i:3d}] âœ“ {end_t - start_t:.1f}s", flush=True)
    return temp_out

def render_final_video(segments: List[Segment], input_path: str, output_path: str):
    """Optimized final rendering with smart processing."""
    temp_dir = "temp_spliceo_v2"
    os.makedirs(temp_dir, exist_ok=True)
    
    info = get_video_info(input_path)
    fps = info["fps"]
    has_audio = info["has_audio"]
    orig_w, orig_h = info["width"], info["height"]
    out_w, out_h = get_output_resolution(orig_w, orig_h)
    
    print(f"\n{'='*70}")
    print(f"Spliceo V2 Ultra - Performance Mode: {PERFORMANCE_PRESET.upper()}")
    print(f"{'='*70}")
    print(f"Input:  {orig_w}x{orig_h} @ {fps:.1f}fps | {info['duration']:.1f}s")
    gpu_active = check_gpu_support()
    print(f"Output: {out_w}x{out_h} | {'GPU (' + GPU_ENCODER + ')' if gpu_active else 'CPU (libx264)'}")
    print(f"Quality: {'CQ=' + str(CQ_QUALITY) if gpu_active else 'CRF=' + str(CRF_QUALITY)} | Preset={GPU_PRESET if gpu_active else ENCODING_PRESET}")
    print(f"Audio:  {AUDIO_BITRATE} AAC")
    print(f"Workers: {MAX_WORKERS} | Threads: {FFMPEG_THREADS or 'auto'}")
    print(f"Smart Copy: {'ON' if SMART_COPY_MODE else 'OFF'}")
    print(f"{'='*70}\n")
    
    copy_count = sum(1 for s in segments if s.can_copy)
    process_count = sum(1 for s in segments if s.needs_processing and not s.can_copy)
    
    print(f"Segments: {len(segments)} total")
    print(f"  â†’ {copy_count} instant (codec copy)")
    print(f"  â†’ {process_count} processing")
    print(f"\n{'='*70}\n")
    
    render_args = [
        (i, seg, input_path, temp_dir, fps, DEBUG_OVERLAY, has_audio,
         orig_w, orig_h, out_w, out_h)
        for i, seg in enumerate(segments)
    ]
    
    segment_files = []
    failed_segments = []
    
    try:
        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = {executor.submit(render_segment_smart, arg): i 
                      for i, arg in enumerate(render_args)}
            
            for future in futures:
                seg_idx = futures[future]
                try:
                    result = future.result(timeout=MAX_SEGMENT_TIMEOUT)
                    segment_files.append((seg_idx, result))
                except FuturesTimeoutError:
                    print(f"  [{seg_idx:3d}] TIMEOUT!", flush=True)
                    failed_segments.append(seg_idx)
                except Exception as e:
                    print(f"  [{seg_idx:3d}] ERROR: {str(e)[:80]}", flush=True)
                    failed_segments.append(seg_idx)
        
        if not segment_files:
            raise RuntimeError("No segments rendered successfully!")
        
        if failed_segments:
            print(f"\nâš  {len(failed_segments)} segments failed: {failed_segments}")
            print("Continuing with successful segments...\n")
        
        segment_files.sort(key=lambda x: x[0])
        
        print(f"\n{'='*70}")
        print(f"Concatenating {len(segment_files)} segments...")
        print(f"{'='*70}\n")
        
        concat_list = os.path.join(temp_dir, "concat.txt")
        with open(concat_list, "w") as f:
            for _, sf in segment_files:
                f.write(f"file '{os.path.abspath(sf)}'\n")
        
        print("Final assembly...")
        
        final_cmd = [
            FFMPEG_BIN, "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", concat_list,
            "-c", "copy",
            "-movflags", "+faststart",
            output_path
        ]
        
        run_ffmpeg(final_cmd, timeout=600, show_progress=True)
    
    finally:
        if os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except:
                pass

# =============================================================================
# MAIN HANDLER
# =============================================================================

def handler(job):
    """Main RunPod handler function."""
    print("\n" + "="*70)
    print("Spliceo V2 Ultra - GPU-Optimized Video Editor")
    print("="*70 + "\n")
    
    # Install gdown if not available
    try:
        import gdown
    except ImportError:
        print("ðŸ“¦ Installing gdown for Google Drive downloads...")
        subprocess.check_call(["pip", "install", "-q", "gdown"])
        import gdown
        print("âœ“ gdown installed\n")
    
    # Download input video if not present
    if not os.path.exists(INPUT_VIDEO):
        print(f"ðŸ“¥ Downloading test video from Google Drive...")
        video_file_id = "179n-sYHEwd69Seb2WcqCZS4b5BxV5BNj"
        try:
            download_from_gdrive(video_file_id, INPUT_VIDEO)
            print(f"âœ“ Video downloaded: {INPUT_VIDEO}\n")
        except Exception as e:
            print(f"âŒ Failed to download video: {str(e)}")
            return {"error": f"Failed to download video: {str(e)}"}
    
    # Download edit map if not present
    if not os.path.exists(EDITMAP_JSON):
        print(f"ðŸ“¥ Downloading test edit map from Google Drive...")
        edit_file_id = "1kXnvg8gwgG-qhAD6FWf5K1KX1hh44fiT"
        try:
            download_from_gdrive(edit_file_id, EDITMAP_JSON)
            print(f"âœ“ Edit map downloaded: {EDITMAP_JSON}\n")
        except Exception as e:
            print(f"âŒ Failed to download edit map: {str(e)}")
            return {"error": f"Failed to download edit map: {str(e)}"}
    
    # Validate video file
    try:
        info = get_video_info(INPUT_VIDEO)
        total_duration = info["duration"]
        print(f"âœ“ Video validated: {info['width']}x{info['height']}, {total_duration:.1f}s\n")
    except Exception as e:
        print(f"âŒ Invalid video file: {str(e)}")
        return {"error": f"Invalid video file: {str(e)}"}
    
    # Load and parse edit map
    try:
        print(f"ðŸ“‹ Loading edit map...")
        with open(EDITMAP_JSON, "r") as f:
            data = json.load(f)
        
        edits, subtitles = parse_edit_map(data)
        print(f"âœ“ Found {len(edits)} edits, {len(subtitles)} subtitles\n")
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in edit map: {str(e)}")
        return {"error": f"Invalid JSON in edit map: {str(e)}"}
    except Exception as e:
        print(f"âŒ Failed to parse edit map: {str(e)}")
        return {"error": f"Failed to parse edit map: {str(e)}"}
    
    # Create segments
    orig_w, orig_h = info["width"], info["height"]
    out_w, out_h = get_output_resolution(orig_w, orig_h)
    
    segments = create_segments(edits, subtitles, total_duration, 
                               orig_w, orig_h, out_w, out_h)
    
    total_duration_seg = sum(s.duration for s in segments)
    print(f"ðŸ“Š Timeline: {len(segments)} segments | {total_duration_seg:.1f}s total\n")
    
    # Start rendering
    start_time = time.time()
    
    try:
        render_final_video(segments, INPUT_VIDEO, OUTPUT_VIDEO)
        
        end_time = time.time()
        elapsed = end_time - start_time
        
        # Calculate statistics
        file_size = os.path.getsize(OUTPUT_VIDEO) / (1024 * 1024)
        original_size = os.path.getsize(INPUT_VIDEO) / (1024 * 1024)
        compression = ((original_size - file_size) / original_size) * 100
        
        print(f"\n{'='*70}")
        print("âœ… SUCCESS!")
        print(f"{'='*70}")
        print(f"Output: {OUTPUT_VIDEO}")
        print(f"Time: {elapsed/60:.2f} min ({elapsed:.1f}s)")
        print(f"Size: {file_size:.1f} MB (was {original_size:.1f} MB)")
        print(f"Compression: {compression:.1f}% smaller")
        print(f"Speed: {total_duration_seg/elapsed:.2f}x realtime")
        print(f"{'='*70}\n")
        
        return {
            "success": True,
            "output_file": OUTPUT_VIDEO,
            "processing_time": elapsed,
            "output_size_mb": file_size,
            "compression_percent": compression,
            "realtime_speed": total_duration_seg/elapsed,
            "segments_processed": len(segments)
        }
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Interrupted by user!")
        return {"error": "Processing interrupted"}
    except Exception as e:
        print(f"\nâŒ ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


# Start RunPod serverless handler
if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})